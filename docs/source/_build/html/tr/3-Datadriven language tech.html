<!DOCTYPE html>
<html class="writer-html5" lang="tr" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Data-driven language technologies &mdash; Language Toolkit 0.1 belgelendirmesi</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/translations.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Dizin" href="genindex.html" />
    <link rel="search" title="Ara" href="search.html" />
    <link rel="next" title="Language data" href="4-Language%20data.html" />
    <link rel="prev" title="Languages and the digital age" href="2-Digital%20age.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> Language Toolkit
          </a>
              <div class="version">
                0.1.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Belgeleri arayın" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="1-Introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="2-Digital%20age.html">Languages and the digital age</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Data-driven language technologies</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#machine-translation">Machine translation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#automatic-speech-recognition">Automatic speech recognition</a></li>
<li class="toctree-l2"><a class="reference internal" href="#text-to-speech">Text-to-speech</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="4-Language%20data.html">Language data</a></li>
<li class="toctree-l1"><a class="reference internal" href="5-Case%20studies.html">Case studies</a></li>
<li class="toctree-l1"><a class="reference internal" href="6-Good%20practices.html">Good practices</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Language Toolkit</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Data-driven language technologies</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/3-Datadriven language tech.rst.txt" rel="nofollow"> Sayfa kaynağını görüntüle</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="data-driven-language-technologies">
<h1>Data-driven language technologies<a class="headerlink" href="#data-driven-language-technologies" title="Bu başlık için kalıcı bağlantı"></a></h1>
<p>The digital revolution is here with us and Artificial Intelligence (AI) is a key technological enabler as it offers a range of new opportunities to break down existing barriers to human development and social inclusion. One are that is powered by AI is Language technology which makes it possible to interact with our phones through digital assistants, translate websites and documents with a few clicks, increase accessibility of videos with automatic captioning etc.</p>
<p>The main motor behind these is the advancement of the field <strong>Natural Language Processing (NLP)</strong>. But what does NLP entail? Here’s a list of core technologies that fall in the area of this field:</p>
<p>Text-based:</p>
<ul class="simple">
<li><p>Machine translation</p></li>
<li><p>Information retrieval</p></li>
<li><p>Sentiment analysis</p></li>
<li><p>Information extraction</p></li>
<li><p>Question answering</p></li>
<li><p>Text summarization</p></li>
<li><p>Named-entity recognition</p></li>
</ul>
<p>Speech-based:</p>
<ul class="simple">
<li><p>Automatic speech recognition</p></li>
<li><p>Text-to-speech synthesis</p></li>
</ul>
<p>The revolutionary aspect of these technologies is that they are <em>data-driven</em>, which means that the intelligence that is created with these tools are collected from large volumes of information–or simply <em>data</em>. For example, in the case of machine translation, the engine “models” translation from a language to the other by looking at a collection of human-translated documents and sentences. Similarly a <em>sentinment analyzer</em> learns how to label if a tweet says good or bad about a company from thousands of tweets labelled by humans as carrying a good or bad sentiment.</p>
<p>This dependency on data is what makes these technologies accessible to some languages and not to the others. The available resources for a language directly influences the possibility of developing an application for a language. As the greatest resource of textual data is the internet, and it is dominated by a few languages, these technologies tend to focus on only a handful of <em>power languages</em> e.g. English, Spanish, Chinese, Arabic etc.</p>
<p>The diagram below by <a class="reference external" href="https://www.microsoft.com/en-us/research/publication/ellora-enabling-low-resource-languages-with-technology/">Microsoft Research Labs India</a> illustrates the hierarchy created by this “power-law” among languages.</p>
<figure class="align-center" id="id1">
<img alt="Classification of languages according to the availability of language technology, tools and resources" src="_images/ellora.png" />
<figcaption>
<p><span class="caption-text">Classification of languages according to the availability of language technology, tools and resources</span><a class="headerlink" href="#id1" title="Bu resmin kalıcı bağlantısı"></a></p>
</figcaption>
</figure>
<section id="machine-translation">
<h2>Machine translation<a class="headerlink" href="#machine-translation" title="Bu başlık için kalıcı bağlantı"></a></h2>
<p>Machine Translation (MT) is defined as the automatic conversion of a sequence of symbols in one language to a sequence of symbols in another language. It has evolved through years from rule-based to statistical approaches, which modeled the probabilities of mappings between sub-phrases between translations. These probabilities are learned in a statistical fashion from parallel texts where sentence-aligned translations are available in the languages involved (referred as source and target languages). The diagram below illustrates the modelling of translating the word “sure” in English to Spanish using translations made in the UN Parliament.</p>
<figure class="align-center" id="id2">
<img alt="Extracting statistics of translations from parallel data" src="_images/sure-seguro.png" />
<figcaption>
<p><span class="caption-text">Extracting statistics of translations from parallel data</span><a class="headerlink" href="#id2" title="Bu resmin kalıcı bağlantısı"></a></p>
</figcaption>
</figure>
<p>Machine translation services like Google Translate and DeepL have made their way into reliable tools for translators and also regular folk in the recent years. This is largely due to the advancement of <em>deep learning</em> techniques that revolutionized the artificial intelligence field. This new way of modelling introduced in 2014 made 50% fewer word order mistakes, 17% fewer lexical mistakes, 19% fewer grammar mistakes compared to earlier models.</p>
<p>The uses of machine translation are as follows:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p><strong>Assimilation</strong>, emulating a certain document in another language. This use-case enables e.g. reading a news site or technical paper in a language that we don’t understand. We know that it’s not a 100% accurate translation, but it gives the gist to explore further more.</p></li>
<li><p><strong>Communication</strong>, enabling the communication between individuals and organizations e.g. in chat, tourism, e-commerce, lowering the need for a lingua franca.</p></li>
<li><p><strong>Monitoring</strong>, enabling tracing of information in large-scale multilingual documents e.g. discovering international trends in Twitter.</p></li>
<li><p><strong>Assistance</strong>, improving translation workflows e.g. computer-assisted translation, post-editing.</p></li>
</ol>
</div></blockquote>
<p>MT has also become an essential tool in language learning. <a class="reference external" href="https://ojs.uv.es/index.php/attic/article/view/2228">A recent work by Duke University</a> studies their usage among university level language learners beside other classic tools like dictionaries and thesauri. They report that 76% of the students enrolled in a Spanish class use web-based MT tools like Google Translate during their studies.</p>
<p>Finally, MT has also been proposed as a documentation and preservation tool for endangered languages by Bird and Chiang in their paper <a class="reference external" href="https://aclanthology.org/C12-2013/">Machine translation for language preservation</a>. Directly quoting from their paper: “… when source texts are translated into a major world language, we guarantee that the language documentation will be interpretable even after the language has fallen out of use. Second, when a surviving speaker can identify errors in the output of an MT system, we have timely evidence of those areas of grammar and lexicon that need better coverage while there is still time to collect more. These tasks of producing and correcting translations can be performed by speakers of the language without depending on the intervention of outside linguists. Furthermore, we sidestep the need for linguistic resources like treebanks and wordnets, which are expensive to create and which depend on the existence of morphological, syntactic, and semantic analyses of the language.”</p>
<p>This innovative way of language documentation reduces the effort into mere translation collection since MT development relies on this type of data.</p>
</section>
<section id="automatic-speech-recognition">
<h2>Automatic speech recognition<a class="headerlink" href="#automatic-speech-recognition" title="Bu başlık için kalıcı bağlantı"></a></h2>
<p>Automatic speech recognition (ASR) is the conversion of speech in its acoustic form into a symbolic form such as words or letters. It is the probabilistic modelling of the question ”What is the most probable word sequence among all possible word sequences given an acoustic input?”. Diagram below illustrates this process. Speech signal captured by a microphone is first encoded into a sequence of acoustic feature vectors. Following, the acoustic feature vectors are decoded into the words that represent the linguistic information that lies in the speech signal.</p>
<figure class="align-center" id="id3">
<a class="reference internal image-reference" href="_images/asr.png"><img alt="Automatic speech recognition is modelling the question ”What is the most probable word sequence among all possible word sequences given an acoustic input?”" src="_images/asr.png" style="width: 600px;" /></a>
<figcaption>
<p><span class="caption-text">A simple diagram of automatic speech recognition</span><a class="headerlink" href="#id3" title="Bu resmin kalıcı bağlantısı"></a></p>
</figcaption>
</figure>
<p>Developing an automatic speech recognition system for a language is dependant on the following type of data:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Collection of short speech audio recordings from many speakers and their text transcriptions</p></li>
<li><p>A large text corpus</p></li>
<li><p>Phonetic pronunciation dictionary (This is optional in more modern technologies)</p></li>
</ol>
</div></blockquote>
<p>ASR has progressed significantly in the last decade again thanks to the advent of deep-learning. In September 2017, Microsoft announced <a class="reference external" href="https://www.microsoft.com/en-us/research/publication/toward-human-parity-conversational-speech-recognition/">their results</a> for an English speech recognition system that could achieve better-than-human performance in speech transcription. Their system was based on a dataset of 200M transcribed words from conversational speech. These developments have had great impact already as virtual assistants have become a cotidian application, voice search and automatic transcription of audio.</p>
</section>
<section id="text-to-speech">
<h2>Text-to-speech<a class="headerlink" href="#text-to-speech" title="Bu başlık için kalıcı bağlantı"></a></h2>
<p>Text-to-speech (or speech synthesis) involves production of a human-like speech given a text input with a computer. Before the advent of deep learning, there were two main approaches to text-to-speech (TTS) synthesis: concatenative TTS, and parametric TTS. Concatenative TTS, also called unit selection, combines short pre-recorded audio clips called units to synthesise the desired text. Concatenative TTS can provide a good performance in terms of speech quality but the cut and stitch procedure means a lack of naturalness. Parametric TTS relies on statistical methods by generating speech with a combination of parameters like F0 and energy, modelling the human speech production.</p>
<p>Currently, most modern TTS systems rely on deep-learning methods. The deep neural networks are trained using a large amount of recorded speech and the associated text transcriptions. In contrast to ASR training data, they are usually collected from a single speaker. The resulting TTS system is able to replicate the voice of this particular speaker.</p>
<p>TTS is important in making computers accessible to blind or partially sighted people as it enables them to “read” from the screen. TTS technology can be linked to any written input in a variety of languages, e.g. automatic pronunciation of words from an online dictionary, reading aloud of a text, interface for a voice assistant etc.</p>
<p>In the case of endangered and minority languages, TTS can aid language learning and language documentation. Students who don’t have access to speakers can study how a sentence is pronounced without assistance from a tutor. It is a permanent record of the language as it will persist even after the moment there are no speakers left for the language.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="2-Digital%20age.html" class="btn btn-neutral float-left" title="Languages and the digital age" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Önceki</a>
        <a href="4-Language%20data.html" class="btn btn-neutral float-right" title="Language data" accesskey="n" rel="next">Sonraki <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Telif hakkı 2022, Col·lectivaT SCCL.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">tema</a>
    kullanılarak <a href="https://readthedocs.org">Read the Docs</a> tarafından sağlanmasıyla oluşturuldu.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>